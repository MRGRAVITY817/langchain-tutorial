{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nThere are 8 planets in the solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.',\n",
       " 'There are 8 planets in the solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\")\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "a = llm.predict(\"How many planets are there in the solar system?\")\n",
    "b = chat.predict(\"How many planets are there in the solar system?\")\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='We have a variety of toppings available for our pizzas. Some popular options include classic Margherita with tomato sauce, fresh mozzarella, and basil, or a Quattro Stagioni with artichokes, mushrooms, ham, and olives. We also have options like Prosciutto e Rucola with prosciutto, arugula, and shaved Parmesan, or a Diavola with spicy salami and chili flakes. Feel free to customize your pizza with any toppings you prefer!')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "\tSystemMessage(content=\"You are a professional italian chef.\"),\n",
    "\tAIMessage(content=\"Welcome to the italian restaurant. What would you like to order?\"),\n",
    "\tHumanMessage(content=\"I'd like to order a pizza. What are the toppings?\"),\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Earth and Mars varies depending on their positions in their respective orbits. On average, the distance between Earth and Mars is about 225 million kilometers (140 million miles). However, this distance can range from about 54.6 million kilometers (33.9 million miles) when the two planets are at their closest approach (opposition) to about 401 million kilometers (249 million miles) when they are at their farthest apart (conjunction).'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between the {planet_a} and the {planet_b}?\",)\n",
    "\n",
    "prompt = template.format(planet_a=\"Earth\", planet_b=\"Mars\")\n",
    "\n",
    "chat.predict(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='For a classic Italian pizza, we typically use a thin crust topped with tomato sauce, mozzarella cheese, and various toppings such as pepperoni, mushrooms, bell peppers, onions, olives, and basil. Is there a specific type of pizza you have in mind or any dietary restrictions I should be aware of?')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", \"You are a professional {nationality} chef.\"),\n",
    "\t(\"ai\", \"Welcome to the {nationality} restaurant. What would you like to order?\"),\n",
    "\t(\"human\", \"I'd like to order a {food}. What are the ingredients?\"),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(nationality=\"italian\", food=\"pizza\")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you?']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "\tdef parse(self, text: str) -> str:\n",
    "\t\titems = text.strip().split(\",\")\n",
    "\t\treturn list(map(str.strip, items))\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(\"Hello,how,are,you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'black',\n",
       " 'white',\n",
       " 'pink',\n",
       " 'brown']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", \"\"\"You are a list generating machine. \n",
    "\tEverything you are asked will be answered with a comma separated list of max {max_items}, in lowercase. Do not reply with anything else.\n",
    "\t\"\"\"),\n",
    "\t(\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "\tmax_items=10,\n",
    "\tquestion=\"What are the colors?\"\n",
    ")\n",
    "\n",
    "output = chat.predict_messages(prompt)\n",
    "\n",
    "p.parse(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | chat | CommaOutputParser()\n",
    "\n",
    "chain.invoke({\n",
    "\t\"max_items\": 10,\n",
    "\t\"question\": \"What are the colors?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", \"You are a professional international chef. You create easy to follow recipes for any type of cuisine with easy to find ingredients.\"),\n",
    "\t(\"human\", \"I want to cook a {cuisine} dish. What is the best recipe for beginner?\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\"system\", \"\"\"\n",
    "\t\tYou are a vegetarian chef specialized on making traditional recipes vegetarian. \n",
    "\t\tYou find alternative ingredients and explain their preparation. \n",
    "\t\tYou don't radically modify the recipe. \n",
    "\t\tIf there is no alternative for a food just say you don't know how to replace it\n",
    "\t\"\"\"),\n",
    "\t(\"human\", \"{recipe}\")\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\" : chef_chain} | veg_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "\t\"cuisine\": \"korean\",\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-tutorial-GmViVmTg-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
